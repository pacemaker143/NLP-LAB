{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Perform tokenization (Whitespace, Punctuation-based, Treebank, Tweet, MWE) using NLTK\n",
        "# Use Porter Stemmer and Snowball Stemmer for stemming\n",
        "# Use lemmatization using WordNet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, TreebankWordTokenizer, TweetTokenizer, MWETokenizer\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "text = \"The Uniform Civil Code promotes equality and justice in a diverse nation like India.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Whitespace Tokenization\n",
        "whitespace_tokens = text.split()\n",
        "print(\"Whitespace Tokens:\", whitespace_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Punctuation-based Tokenization\n",
        "punctuation_tokens = word_tokenize(text)\n",
        "print(\"Punctuation Tokens:\", punctuation_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Treebank Tokenization\n",
        "treebank = TreebankWordTokenizer()\n",
        "treebank_tokens = treebank.tokenize(text)\n",
        "print(\"Treebank Tokens:\", treebank_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Tweet Tokenization\n",
        "tweet = TweetTokenizer()\n",
        "tweet_tokens = tweet.tokenize(text)\n",
        "print(\"Tweet Tokens:\", tweet_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Multi-Word Expression (MWE) Tokenization\n",
        "mwe = MWETokenizer([('Uniform', 'Civil', 'Code'), ('diverse', 'nation')])\n",
        "mwe_tokens = mwe.tokenize(word_tokenize(text))\n",
        "print(\"MWE Tokens:\", mwe_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Stemming\n",
        "porter = PorterStemmer()\n",
        "snowball = SnowballStemmer('english')\n",
        "\n",
        "porter_stems = [porter.stem(word) for word in punctuation_tokens]\n",
        "snowball_stems = [snowball.stem(word) for word in punctuation_tokens]\n",
        "\n",
        "print(\"Porter Stemmer:\", porter_stems)\n",
        "print(\"Snowball Stemmer:\", snowball_stems)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in punctuation_tokens]\n",
        "print(\"Lemmatized Words:\", lemmatized_words)"
      ]
    }
  ]
}

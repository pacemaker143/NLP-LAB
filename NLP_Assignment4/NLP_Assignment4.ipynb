{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Build a Named Entity Recognition (NER) system\n",
        "# Measure Accuracy, Precision, Recall, and F1-score\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Sample real-world (news-style) NER dataset\n",
        "sentences = [\n",
        "    [\"John\", \"lives\", \"in\", \"New\", \"York\"],\n",
        "    [\"Apple\", \"was\", \"founded\", \"by\", \"Steve\", \"Jobs\"],\n",
        "    [\"India\", \"won\", \"the\", \"cricket\", \"match\"]\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    [\"B-PER\", \"O\", \"O\", \"B-LOC\", \"I-LOC\"],\n",
        "    [\"B-ORG\", \"O\", \"O\", \"O\", \"B-PER\", \"I-PER\"],\n",
        "    [\"B-LOC\", \"O\", \"O\", \"O\", \"O\"]\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Create word and tag vocabularies\n",
        "word2idx = {\"<PAD>\": 0}\n",
        "tag2idx = {\"O\": 0}\n",
        "\n",
        "for sent in sentences:\n",
        "    for word in sent:\n",
        "        if word not in word2idx:\n",
        "            word2idx[word] = len(word2idx)\n",
        "\n",
        "for tag_seq in labels:\n",
        "    for tag in tag_seq:\n",
        "        if tag not in tag2idx:\n",
        "            tag2idx[tag] = len(tag2idx)\n",
        "\n",
        "idx2tag = {v: k for k, v in tag2idx.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Custom Dataset class\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, sentences, labels):\n",
        "        self.X = [[word2idx[w] for w in sent] for sent in sentences]\n",
        "        self.y = [[tag2idx[t] for t in tag_seq] for tag_seq in labels]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.X[idx]), torch.tensor(self.y[idx])\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# NER Model using BiLSTM\n",
        "class NERModel(nn.Module):\n",
        "    def __init__(self, vocab_size, tag_size, embed_dim=64, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, tag_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        return self.fc(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Training the model\n",
        "dataset = NERDataset(sentences, labels)\n",
        "loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "model = NERModel(len(word2idx), len(tag2idx))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    for X, y in loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs.view(-1, len(tag2idx)), y.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print(\"Training completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Evaluation: Accuracy, Precision, Recall, F1-score\n",
        "model.eval()\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X, y in loader:\n",
        "        outputs = model(X)\n",
        "        predictions = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "        true_labels.extend(y.view(-1).tolist())\n",
        "        pred_labels.extend(predictions.view(-1).tolist())\n",
        "\n",
        "accuracy = accuracy_score(true_labels, pred_labels)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    true_labels, pred_labels, average=\"macro\"\n",
        ")\n",
        "\n",
        "print(\"Accuracy :\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall   :\", recall)\n",
        "print(\"F1 Score :\", f1)\n"
      ]
    }
  ]
}
